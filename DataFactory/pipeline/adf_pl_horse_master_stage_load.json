{
	"name": "adf_pl_horse_master_stage_load",
	"properties": {
		"activities": [
			{
				"name": "Load Initiation",
				"description": "Policy version identification",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "adf_pl_params",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup.py",
					"parameters": [
						"stage_load",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value",
						"@activity('adf_pl_params').output.value[5].param_value",
						"@activity('adf_pl_params').output.value[6].param_value",
						"RAW_HISTORY_XML",
						"stage",
						"@activity('adf_pl_params').output.value[3].param_value"
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "POLICY_ACTION_JOB Stage load",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "Load Initiation",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup.py",
					"parameters": [
						"stage_load",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value",
						"@activity('adf_pl_params').output.value[5].param_value",
						"@activity('adf_pl_params').output.value[6].param_value",
						"POLICY_ACTION_JOB",
						"stage",
						"@activity('adf_pl_params').output.value[3].param_value"
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "Policy_Stg Load",
				"description": "Loading the stage tables under Policy\n",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "POLICY_ACTION_JOB Stage load",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "adf_pl_horse_policy_stg_load",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			},
			{
				"name": "Policy_LOB_Stg Load",
				"description": "Loading the stage tables under Policy_Lob\n",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "Policy_Stg Load",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "adf_pl_horse_policy_lob_stg_load",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			},
			{
				"name": "Policy_LOB_Risk_Unit_Stg Load",
				"description": "Loading the stage tables under Policy_LOB Risk_Unit\n",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "Policy_LOB_Stg Load",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "adf_pl_horse_policy_risk_unit_stg_load",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			},
			{
				"name": "Policy_Coverage_Stg Load",
				"description": "Loading the stage tables under POLICY COVERAGE\n",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "Policy_LOB_Risk_Unit_Stg Load",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "adf_pl_horse_policy_coverage_stg_load",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			},
			{
				"name": "adf_pl_params",
				"type": "Lookup",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "DelimitedTextSource",
						"storeSettings": {
							"type": "AzureBlobStorageReadSettings",
							"recursive": true,
							"enablePartitionDiscovery": false
						},
						"formatSettings": {
							"type": "DelimitedTextReadSettings"
						}
					},
					"dataset": {
						"referenceName": "E2_HORSE_PARAMS",
						"type": "DatasetReference"
					},
					"firstRowOnly": false
				}
			},
			{
				"name": "notify_failure",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "Load Initiation",
						"dependencyConditions": [
							"Failed"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup.py",
					"parameters": [
						"notify",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value",
						"failed",
						"@concat(activity('adf_pl_params').output.value[0].param_value,' ', activity('adf_pl_params').output.value[1].param_value,' Job Failed due to 0 records available for the date range from source.<br> Clearing all audit entries')"
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "Clear Audit Entry",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "notify_failure",
						"dependencyConditions": [
							"Failed"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup.py",
					"parameters": [
						"clear_audit",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value",
						""
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			}
		],
		"folder": {
			"name": "HORSE"
		},
		"annotations": []
	}
}