{
	"name": "bkp_adf_pl_horse_master_load",
	"properties": {
		"activities": [
			{
				"name": "Intiate_Batch",
				"description": "",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "adf_pl_params",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup_4.py",
					"parameters": [
						"create_batch",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value"
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "adf_pl_params",
				"type": "Lookup",
				"dependsOn": [],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"source": {
						"type": "DelimitedTextSource",
						"storeSettings": {
							"type": "AzureBlobStorageReadSettings",
							"recursive": true,
							"enablePartitionDiscovery": false
						},
						"formatSettings": {
							"type": "DelimitedTextReadSettings"
						}
					},
					"dataset": {
						"referenceName": "E2_HORSE_PARAMS",
						"type": "DatasetReference"
					},
					"firstRowOnly": false
				}
			},
			{
				"name": "POLICY_ACTION_JOB Stage load",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "Execute Horse Raw load",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup_4.py",
					"parameters": [
						"stage_load",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value",
						"@activity('adf_pl_params').output.value[5].param_value",
						"@activity('adf_pl_params').output.value[6].param_value",
						"POLICY_ACTION_JOB",
						"stage",
						"@activity('adf_pl_params').output.value[3].param_value"
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "Execute horse",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "POLICY_ACTION_JOB Stage load",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "horse_load",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			},
			{
				"name": "Close_Batch",
				"type": "DatabricksSparkPython",
				"dependsOn": [
					{
						"activity": "Execute horse",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"timeout": "0.12:00:00",
					"retry": 0,
					"retryIntervalInSeconds": 30,
					"secureOutput": false,
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pythonFile": "dbfs:/FileStore/main_adf_setup.py",
					"parameters": [
						"close_batch",
						"@activity('adf_pl_params').output.value[0].param_value",
						"@activity('adf_pl_params').output.value[1].param_value",
						"@activity('adf_pl_params').output.value[2].param_value",
						"@activity('adf_pl_params').output.value[6].param_value"
					],
					"libraries": [
						{
							"whl": "dbfs:/FileStore/jars/cyberclouddatapipeline/industryclouddatapipeline-0.1.5-py3-none-any.whl"
						}
					]
				},
				"linkedServiceName": {
					"referenceName": "AzureDatabricks",
					"type": "LinkedServiceReference"
				}
			},
			{
				"name": "Execute Horse Raw load",
				"type": "ExecutePipeline",
				"dependsOn": [
					{
						"activity": "Intiate_Batch",
						"dependencyConditions": [
							"Succeeded"
						]
					}
				],
				"policy": {
					"secureInput": false
				},
				"userProperties": [],
				"typeProperties": {
					"pipeline": {
						"referenceName": "adf_pl_horse_history_raw_load",
						"type": "PipelineReference"
					},
					"waitOnCompletion": true
				}
			}
		],
		"folder": {
			"name": "E2_HORSE"
		},
		"annotations": []
	}
}